{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a21d759e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THIS SCRIPT USES *WINDOWS* FILEPATHS. CHANGE FOR LINUX!! (inc the additional 'proj_code' at start for some reason)\n",
      "Imports...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fabia\\Documents\\GitHub\\MetaStableBaselines3\\proj_code\\stable-baselines3-master\\stable-baselines3-master\\stable_baselines3\\common\\on_policy_algorithm.py:649: SyntaxWarning: invalid escape sequence '\\e'\n",
      "  Find risk bound \\epsilon and performance guarantee \\\\tilde{J} s.t. {policy} is certifiably robust with {confidence_level}.\n",
      "C:\\Users\\fabia\\Documents\\GitHub\\MetaStableBaselines3\\proj_code\\stable-baselines3-master\\stable-baselines3-master\\stable_baselines3\\common\\on_policy_algorithm.py:672: SyntaxWarning: invalid escape sequence '\\e'\n",
      "  Find risk bound \\epsilon and performance guarantee \\\\tilde{J} s.t. {policy} is certifiably robust with {confidence_level}.\n",
      "C:\\Users\\fabia\\Documents\\GitHub\\MetaStableBaselines3\\proj_code\\stable-baselines3-master\\stable-baselines3-master\\stable_baselines3\\common\\on_policy_algorithm.py:712: SyntaxWarning: invalid escape sequence '\\e'\n",
      "  Find risk bound \\epsilon and performance guarantee \\\\tilde{J} s.t. {policy} is certifiably robust with {confidence_level}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fabia\\anaconda3\\envs\\projdist\\Lib\\site-packages\\gymnasium\\envs\\registration.py:487: UserWarning: \u001b[33mWARN: The environment creator metadata doesn't include `render_modes`, contains: ['render.modes']\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#THIS SCRIPT IS ALL ABOUT TRYING OUT MY SMC FOR THEOREM 1 AND SEEING WHAT HAPPENS!\n",
    "\n",
    "print(\"THIS SCRIPT USES *WINDOWS* FILEPATHS. CHANGE FOR LINUX!! (inc the additional 'proj_code' at start for some reason)\")\n",
    "\n",
    "####################################################################################\n",
    "print(\"Imports...\")\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "import gymnasium as gym\n",
    "\n",
    "from stable_baselines3 import A2C,PPO\n",
    "\n",
    "\n",
    "from stable_baselines3.common.logger import configure\n",
    "\n",
    "\n",
    "import fabian.envs.khazad_dum_gymn \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "####################################################################################\n",
    "print(\"Setting up...\")\n",
    "model_save_path = \"C:\\\\Users\\\\fabia\\\\Documents\\\\GitHub\\\\MetaStableBaselines3\\\\proj_code\\\\saved_models\\\\19May_TestingMAML_A2C\" #simulatenously testing my new maml syntax out and doing PPO (if somethings up, then try A2C with my new maml syntax to see if its my PPO that is wrong or the MAML syntax (too?))\n",
    "\n",
    "device='cpu'\n",
    "adapt_lr =  7e-4\n",
    "adapt_timesteps = 32*4 #for this enviornment, each episode is exactly 32 timesteps, so multiple of 32 means full number of eps experienced for each task\n",
    "eval_timesteps = 100\n",
    "M=1\n",
    "\n",
    "env = gym.make(\"KhazadDum-v1\") # can access wrapped env with \"env.unwrapped\" (e.g. to reset task)\n",
    "env.unwrapped.exp_bonus = 1; env.unwrapped.bridge_bonus_factor = 2 #this should incentivise getting to the target asap, and incentivise going onto the bridge\n",
    "\n",
    "\n",
    "meta_agent = A2C(\"MlpPolicy\", env, verbose=0, learning_rate=adapt_lr, device=device,\n",
    "                 meta_learning=True, M=M, adapt_timesteps=adapt_timesteps, eval_timesteps=eval_timesteps)\n",
    "meta_agent.policy.load_state_dict(torch.load(f\"{model_save_path}\\\\final\", weights_only=True))\n",
    "\n",
    "####################################################################################\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ca43f9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "eta = 0.1\n",
    "gamma = 0.01 #small to be pretty confient in our bounds (therefore they will be pretty poor guarantees i suppose? hopefully that is what should happen -big t!)\n",
    "tasks = 120\n",
    "k=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a462e228",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120/120 [4:10:06<00:00, 125.05s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: [tensor(-0.3141), tensor(-0.5577), tensor(-0.2135), tensor(-0.3919), tensor(-0.5172), tensor(-0.3621), tensor(-0.1571), tensor(-0.3230), tensor(-0.2274), tensor(-0.1900), tensor(-0.2169), tensor(-0.5554), tensor(-0.6933), tensor(-0.2097), tensor(-0.1958), tensor(0.0462), tensor(-0.0262), tensor(-0.2409), tensor(-0.2495), tensor(-0.6754), tensor(-0.9721), tensor(-0.3820), tensor(-0.4854), tensor(-0.2329), tensor(-1.1191), tensor(-0.3772), tensor(-0.8377), tensor(0.0399), tensor(-0.6654), tensor(-0.2523)], 1: [tensor(-0.1778), tensor(0.0896), tensor(0.0017), tensor(0.0360), tensor(-0.2491), tensor(0.0012), tensor(0.0573), tensor(0.0388), tensor(0.0579), tensor(0.0247), tensor(0.0590), tensor(0.0332), tensor(-0.2069), tensor(0.0157), tensor(0.0598), tensor(-0.1045), tensor(0.0345), tensor(0.0709), tensor(-0.1333), tensor(-0.0299), tensor(-0.2141), tensor(0.0609), tensor(0.0623), tensor(0.0498), tensor(0.0666), tensor(-0.1485), tensor(0.0562), tensor(0.0399), tensor(0.0742), tensor(0.0332)], 2: [tensor(0.0643), tensor(-0.1683), tensor(-0.3226), tensor(-0.4007), tensor(-0.3149), tensor(-0.8693), tensor(-0.7274), tensor(-0.1579), tensor(-0.0941), tensor(0.0245), tensor(-0.1287), tensor(0.0415), tensor(-0.4997), tensor(-0.3249), tensor(-0.5219), tensor(-0.1293), tensor(-0.2541), tensor(-0.2979), tensor(-0.5481), tensor(-0.0490), tensor(-0.4236), tensor(0.0047), tensor(-0.5176), tensor(-0.3596), tensor(0.0356), tensor(0.0166), tensor(-0.2495), tensor(-0.3823), tensor(0.0408), tensor(-0.4661)], 3: [tensor(0.0481), tensor(-1.0225), tensor(-0.1426), tensor(-0.6254), tensor(0.0262), tensor(-0.4706), tensor(-0.0623), tensor(0.0520), tensor(-0.2643), tensor(-0.3288), tensor(-0.4954), tensor(-0.1815), tensor(-0.4775), tensor(-0.1402), tensor(-0.2779), tensor(0.0394), tensor(-0.7029), tensor(-0.0149), tensor(-0.2692), tensor(-0.3527), tensor(-0.1450), tensor(-0.2630), tensor(0.0668), tensor(-0.5307), tensor(-0.2468), tensor(0.0244), tensor(-0.2572), tensor(-0.9292), tensor(-0.4837), tensor(-0.0127)], 4: [tensor(-0.3802), tensor(-0.1908), tensor(0.0913), tensor(-0.2157), tensor(0.0287), tensor(-0.2991), tensor(-0.1823), tensor(-0.2109), tensor(0.0395), tensor(0.0388), tensor(0.0367), tensor(-0.0591), tensor(-0.1659), tensor(-0.2305), tensor(-0.2264), tensor(-0.3808), tensor(-0.1457), tensor(0.0169), tensor(0.0518), tensor(0.0649), tensor(-0.2959), tensor(0.0541), tensor(-0.1366), tensor(-0.0261), tensor(-0.4125), tensor(-0.5365), tensor(-0.2841), tensor(-0.2189), tensor(0.0669), tensor(0.0734)], 5: [tensor(-0.2675), tensor(0.0207), tensor(-0.3625), tensor(-0.2860), tensor(0.0725), tensor(-0.3453), tensor(0.0479), tensor(0.0315), tensor(0.0283), tensor(-0.1576), tensor(-0.3460), tensor(-0.3084), tensor(-0.4445), tensor(0.0346), tensor(0.0268), tensor(0.0867), tensor(0.0385), tensor(0.0388), tensor(-0.1991), tensor(0.0510), tensor(0.0885), tensor(0.0353), tensor(0.0055), tensor(-0.2648), tensor(0.0375), tensor(-0.2119), tensor(-0.1841), tensor(-0.2252), tensor(-0.3345), tensor(0.0497)], 6: [tensor(-0.1726), tensor(-0.1627), tensor(-0.1794), tensor(0.0380), tensor(-0.1329), tensor(0.0226), tensor(-0.4766), tensor(-0.0415), tensor(0.0576), tensor(-0.1770), tensor(0.0357), tensor(0.0343), tensor(0.0212), tensor(-0.1846), tensor(0.0455), tensor(0.0493), tensor(0.0701), tensor(0.0416), tensor(-0.2704), tensor(0.0747), tensor(-0.1715), tensor(0.0803), tensor(0.0391), tensor(0.0655), tensor(0.0552), tensor(0.0414), tensor(0.0168), tensor(0.0471), tensor(0.0174), tensor(-0.2160)], 7: [tensor(0.0303), tensor(0.0373), tensor(-0.1801), tensor(0.0423), tensor(-0.1671), tensor(0.0469), tensor(-0.4657), tensor(0.0558), tensor(-0.1882), tensor(-0.6044), tensor(0.0271), tensor(-0.1750), tensor(-0.1748), tensor(-0.1823), tensor(-0.1725), tensor(0.0081), tensor(0.0447), tensor(0.0098), tensor(0.0066), tensor(0.0474), tensor(0.0342), tensor(-0.2137), tensor(0.0216), tensor(0.0241), tensor(-0.0075), tensor(0.0444), tensor(0.0055), tensor(0.0016), tensor(0.0387), tensor(-0.0165)], 8: [tensor(-0.1464), tensor(-0.1820), tensor(0.0556), tensor(-0.1745), tensor(-0.1526), tensor(-0.3523), tensor(0.0334), tensor(0.0261), tensor(0.0333), tensor(-0.3027), tensor(0.0044), tensor(-0.1247), tensor(-0.1986), tensor(-0.3246), tensor(0.0124), tensor(-0.2741), tensor(0.0003), tensor(-0.0372), tensor(0.0347), tensor(0.0434), tensor(-0.1043), tensor(-0.0338), tensor(-0.1992), tensor(-0.1409), tensor(-0.1254), tensor(-0.1790), tensor(-0.1377), tensor(-0.1383), tensor(0.0618), tensor(-0.2604)], 9: [tensor(0.0735), tensor(-0.2011), tensor(0.0597), tensor(0.0392), tensor(0.0015), tensor(0.0514), tensor(0.0748), tensor(-0.1362), tensor(0.0594), tensor(0.0240), tensor(0.0302), tensor(0.0677), tensor(-0.1928), tensor(0.0486), tensor(0.0154), tensor(0.0390), tensor(0.0603), tensor(0.0343), tensor(0.0645), tensor(-0.0203), tensor(0.0230), tensor(0.0462), tensor(0.0460), tensor(0.0665), tensor(-0.1171), tensor(0.0194), tensor(-0.2255), tensor(-0.0022), tensor(0.0534), tensor(0.0663)], 10: [tensor(0.0417), tensor(0.0047), tensor(0.0264), tensor(-0.2634), tensor(0.0170), tensor(0.0402), tensor(-0.2421), tensor(-0.4575), tensor(0.0724), tensor(0.0582), tensor(0.0197), tensor(0.0357), tensor(-0.0008), tensor(-0.1691), tensor(0.0409), tensor(0.0497), tensor(-0.1781), tensor(0.0410), tensor(0.0977), tensor(0.0759), tensor(-0.5275), tensor(0.0479), tensor(0.0786), tensor(0.0472), tensor(0.0653), tensor(0.0752), tensor(0.0078), tensor(0.0482), tensor(0.0311), tensor(0.0272)], 11: [tensor(-0.2267), tensor(0.0005), tensor(0.0173), tensor(0.0344), tensor(0.0463), tensor(0.0762), tensor(0.0224), tensor(0.0063), tensor(0.0682), tensor(0.0081), tensor(0.0403), tensor(-0.3299), tensor(0.0208), tensor(0.0721), tensor(0.0372), tensor(0.0266), tensor(-0.1405), tensor(0.0578), tensor(0.0432), tensor(0.0378), tensor(-0.3545), tensor(-0.3613), tensor(0.0366), tensor(-0.1753), tensor(0.0121), tensor(0.0187), tensor(0.0030), tensor(0.0213), tensor(-0.0008), tensor(0.0188)], 12: [tensor(0.0089), tensor(0.0542), tensor(-0.2390), tensor(0.0177), tensor(0.0825), tensor(-0.0030), tensor(-0.0239), tensor(-0.0200), tensor(-0.1864), tensor(0.0441), tensor(0.0428), tensor(-0.1681), tensor(0.0437), tensor(0.0067), tensor(0.0078), tensor(0.0640), tensor(-0.2035), tensor(0.0435), tensor(0.0097), tensor(0.0537), tensor(0.0602), tensor(0.0531), tensor(-0.1558), tensor(0.0544), tensor(0.0628), tensor(0.0292), tensor(-0.0084), tensor(0.0228), tensor(-0.1927), tensor(-0.1351)], 13: [tensor(0.0675), tensor(-0.0952), tensor(-0.2318), tensor(-0.4418), tensor(-0.1361), tensor(-0.6107), tensor(0.0466), tensor(-0.3591), tensor(-0.0130), tensor(-0.4767), tensor(0.0573), tensor(0.0765), tensor(-0.1915), tensor(-0.5017), tensor(0.0512), tensor(-0.1174), tensor(0.0737), tensor(0.0553), tensor(-0.3495), tensor(-0.1065), tensor(-0.1740), tensor(-0.1085), tensor(0.0187), tensor(-0.0098), tensor(-0.1471), tensor(-0.4071), tensor(-0.2172), tensor(-0.1641), tensor(-0.1919), tensor(-0.0097)], 14: [tensor(0.0359), tensor(0.0232), tensor(0.0549), tensor(0.0788), tensor(-0.4418), tensor(0.0820), tensor(-0.1601), tensor(-0.1587), tensor(0.0354), tensor(-0.0449), tensor(0.0469), tensor(0.0244), tensor(-0.0683), tensor(0.0430), tensor(-0.3294), tensor(-0.1477), tensor(-0.1830), tensor(0.0327), tensor(-0.0297), tensor(0.0187), tensor(0.0333), tensor(0.0158), tensor(0.0451), tensor(-0.3990), tensor(-0.4222), tensor(0.0136), tensor(-0.0166), tensor(0.0586), tensor(-0.2047), tensor(-0.0130)], 15: [tensor(0.0110), tensor(0.0470), tensor(0.0080), tensor(0.0762), tensor(0.0128), tensor(0.0251), tensor(-0.1908), tensor(0.0599), tensor(-0.0420), tensor(0.0078), tensor(0.0420), tensor(0.0394), tensor(0.0580), tensor(0.0544), tensor(0.0203), tensor(0.0091), tensor(0.0605), tensor(-0.1507), tensor(0.0676), tensor(0.0403), tensor(-0.1889), tensor(0.0514), tensor(0.0495), tensor(-0.0817), tensor(0.0276), tensor(0.0884), tensor(0.0530), tensor(0.0171), tensor(-0.1381), tensor(0.0292)], 16: [tensor(0.0153), tensor(-0.2024), tensor(0.0114), tensor(-0.1892), tensor(-0.4175), tensor(0.0404), tensor(-0.2517), tensor(0.0508), tensor(-0.0278), tensor(-0.7129), tensor(-0.0256), tensor(-0.0748), tensor(-0.1083), tensor(-0.2121), tensor(-0.2486), tensor(-0.2213), tensor(-0.0240), tensor(-0.3406), tensor(-0.2248), tensor(-0.2944), tensor(-0.1565), tensor(-0.3703), tensor(-0.4513), tensor(-0.2666), tensor(-0.5014), tensor(-0.1509), tensor(-0.3194), tensor(0.0154), tensor(-0.2292), tensor(-0.5482)], 17: [tensor(-0.2481), tensor(0.0680), tensor(-0.2527), tensor(-0.2585), tensor(-0.2535), tensor(0.0391), tensor(-0.0152), tensor(-0.1875), tensor(0.0002), tensor(-0.3727), tensor(-0.1891), tensor(-0.0120), tensor(-0.0221), tensor(-0.2172), tensor(0.0386), tensor(-0.2378), tensor(0.0055), tensor(-0.1755), tensor(0.0097), tensor(0.0341), tensor(-0.2601), tensor(-0.1629), tensor(-0.1454), tensor(-0.1362), tensor(-0.0675), tensor(0.0115), tensor(-0.1814), tensor(-0.2693), tensor(-0.0248), tensor(-0.2249)], 18: [tensor(0.0057), tensor(0.0499), tensor(0.0217), tensor(0.0538), tensor(0.0531), tensor(0.0569), tensor(-0.2051), tensor(0.0105), tensor(0.0258), tensor(0.0023), tensor(0.0902), tensor(0.0104), tensor(-0.0320), tensor(0.0399), tensor(-0.0459), tensor(0.0516), tensor(-0.0002), tensor(0.0304), tensor(0.0310), tensor(-0.2579), tensor(0.0382), tensor(0.0655), tensor(0.0564), tensor(0.0244), tensor(0.0134), tensor(0.0337), tensor(0.0945), tensor(0.0703), tensor(-0.0054), tensor(0.0743)], 19: [tensor(-0.5326), tensor(0.0656), tensor(-0.1837), tensor(0.0312), tensor(-0.0448), tensor(-0.0678), tensor(0.0063), tensor(0.0398), tensor(0.0529), tensor(-0.3453), tensor(0.0041), tensor(0.0386), tensor(-0.2123), tensor(-0.1084), tensor(0.0201), tensor(-0.1952), tensor(0.0152), tensor(0.0195), tensor(0.0722), tensor(-0.3858), tensor(-0.1984), tensor(-0.2447), tensor(0.0484), tensor(-0.1530), tensor(-0.0203), tensor(-0.2322), tensor(0.0044), tensor(-0.1643), tensor(0.0097), tensor(0.0973)], 20: [tensor(-0.6492), tensor(-0.0947), tensor(0.0298), tensor(-0.4861), tensor(-0.4268), tensor(-0.1799), tensor(-0.1470), tensor(-0.1190), tensor(0.0541), tensor(-0.2243), tensor(0.0505), tensor(-0.0232), tensor(-0.4348), tensor(-0.2455), tensor(0.0494), tensor(-0.0104), tensor(-0.3019), tensor(-0.2877), tensor(-0.4754), tensor(0.0071), tensor(-0.1249), tensor(-0.1316), tensor(0.0569), tensor(-0.1709), tensor(-0.2648), tensor(0.0201), tensor(-0.2193), tensor(-0.1931), tensor(0.0188), tensor(-0.1568)], 21: [tensor(0.0109), tensor(0.0437), tensor(0.0188), tensor(0.0244), tensor(0.0054), tensor(0.0254), tensor(-0.3374), tensor(0.0264), tensor(-0.0186), tensor(0.0197), tensor(0.0371), tensor(0.0596), tensor(0.0437), tensor(0.0486), tensor(0.0874), tensor(-0.0286), tensor(-0.4230), tensor(0.0239), tensor(0.0483), tensor(0.0657), tensor(0.0295), tensor(0.0389), tensor(0.0662), tensor(0.0891), tensor(0.0134), tensor(0.0650), tensor(0.0071), tensor(-0.1982), tensor(-0.2326), tensor(0.0106)], 22: [tensor(0.0293), tensor(0.0858), tensor(0.0093), tensor(-0.0464), tensor(0.0128), tensor(-0.0575), tensor(0.0315), tensor(0.0403), tensor(0.0662), tensor(0.0565), tensor(-0.2208), tensor(0.0109), tensor(0.0321), tensor(0.0949), tensor(-0.2736), tensor(0.0332), tensor(-0.2477), tensor(-0.2925), tensor(-0.2513), tensor(0.0158), tensor(-0.0358), tensor(-0.1386), tensor(-0.0176), tensor(0.0405), tensor(-0.1802), tensor(-0.3115), tensor(0.0628), tensor(-0.0692), tensor(-0.1129), tensor(-0.1265)], 23: [tensor(-0.3543), tensor(-0.3981), tensor(-0.2202), tensor(-0.3536), tensor(-0.5272), tensor(-0.2007), tensor(0.0129), tensor(-0.5135), tensor(-0.1173), tensor(-0.3766), tensor(-0.4686), tensor(-0.6485), tensor(-0.5501), tensor(-0.2710), tensor(-1.1169), tensor(0.0022), tensor(-0.2370), tensor(-0.5452), tensor(-0.2207), tensor(-0.2533), tensor(-0.5990), tensor(0.0511), tensor(-0.4166), tensor(-0.6430), tensor(-0.3030), tensor(0.0025), tensor(-0.1551), tensor(-0.4542), tensor(0.0386), tensor(-0.2189)], 24: [tensor(-0.1638), tensor(-0.3700), tensor(-0.0884), tensor(-0.1965), tensor(0.0352), tensor(0.0492), tensor(0.0173), tensor(0.0082), tensor(0.0341), tensor(0.0412), tensor(0.0104), tensor(-0.4399), tensor(0.0556), tensor(0.0395), tensor(0.0424), tensor(-0.0184), tensor(0.0650), tensor(0.0220), tensor(0.0678), tensor(-0.4293), tensor(-0.1561), tensor(-0.1063), tensor(0.0464), tensor(-0.0016), tensor(-0.1776), tensor(0.0506), tensor(-0.1760), tensor(0.0865), tensor(0.0576), tensor(0.1101)], 25: [tensor(0.0215), tensor(0.0652), tensor(0.0338), tensor(-0.2345), tensor(0.0845), tensor(-0.1196), tensor(0.0292), tensor(0.0048), tensor(-0.1557), tensor(0.0256), tensor(-0.1389), tensor(0.0697), tensor(0.0566), tensor(0.0675), tensor(-0.5027), tensor(-0.1709), tensor(0.0558), tensor(0.0147), tensor(0.0512), tensor(0.0388), tensor(0.0253), tensor(0.0339), tensor(0.0425), tensor(0.0411), tensor(-0.1717), tensor(0.0699), tensor(0.0369), tensor(0.0245), tensor(0.0365), tensor(-0.1195)], 26: [tensor(-0.1886), tensor(0.0153), tensor(-0.0985), tensor(0.0396), tensor(0.0634), tensor(-0.1615), tensor(0.0593), tensor(-0.1880), tensor(0.0554), tensor(0.0273), tensor(0.0326), tensor(0.0091), tensor(0.0763), tensor(0.0619), tensor(-0.2367), tensor(-0.1532), tensor(-0.3340), tensor(0.0163), tensor(-0.2150), tensor(-0.0186), tensor(0.0450), tensor(0.0034), tensor(-0.0144), tensor(0.0678), tensor(-0.1454), tensor(-0.0027), tensor(0.0217), tensor(0.0525), tensor(-0.1602), tensor(0.0474)], 27: [tensor(-0.9194), tensor(0.0312), tensor(-0.1710), tensor(-0.1946), tensor(-0.0254), tensor(0.0961), tensor(-0.3932), tensor(-0.2552), tensor(-0.6078), tensor(0.0348), tensor(-0.2065), tensor(-0.5814), tensor(-0.1280), tensor(-0.2101), tensor(-0.2453), tensor(-0.3515), tensor(-0.2159), tensor(0.0352), tensor(0.0703), tensor(-0.3870), tensor(-0.0926), tensor(0.0334), tensor(-0.0181), tensor(-0.2712), tensor(-0.3397), tensor(0.0528), tensor(-0.3651), tensor(-0.2822), tensor(-0.2531), tensor(-0.2051)], 28: [tensor(-0.1815), tensor(0.0355), tensor(0.0207), tensor(0.0009), tensor(-0.2012), tensor(0.0670), tensor(-0.2057), tensor(0.0196), tensor(0.0122), tensor(0.0295), tensor(0.0634), tensor(0.1010), tensor(-0.1857), tensor(-0.2219), tensor(0.0717), tensor(0.0970), tensor(0.0685), tensor(-0.5213), tensor(0.0114), tensor(0.0916), tensor(-0.0916), tensor(0.0566), tensor(0.0198), tensor(-0.2252), tensor(-0.1301), tensor(-0.1890), tensor(0.0269), tensor(-0.0002), tensor(-0.0435), tensor(-0.4915)], 29: [tensor(0.0714), tensor(0.0510), tensor(0.0400), tensor(0.0224), tensor(-0.0200), tensor(0.0386), tensor(0.0492), tensor(-0.1169), tensor(0.0295), tensor(0.0544), tensor(0.0914), tensor(-0.1850), tensor(0.0545), tensor(0.0643), tensor(-0.1724), tensor(0.0300), tensor(-0.2274), tensor(0.0275), tensor(0.0022), tensor(0.0708), tensor(0.0252), tensor(0.0383), tensor(0.0097), tensor(0.0678), tensor(0.0545), tensor(0.0706), tensor(0.0373), tensor(-0.0602), tensor(0.0191), tensor(0.0471)], 30: [tensor(0.0329), tensor(-0.1500), tensor(0.0824), tensor(0.0618), tensor(0.0260), tensor(0.0312), tensor(0.0661), tensor(0.0651), tensor(0.0052), tensor(0.0280), tensor(0.0508), tensor(-0.4617), tensor(-0.2515), tensor(0.0357), tensor(-0.0752), tensor(-0.0082), tensor(0.0194), tensor(-0.1733), tensor(0.0060), tensor(0.0859), tensor(0.0364), tensor(0.0061), tensor(0.0258), tensor(0.0382), tensor(0.0230), tensor(-0.2036), tensor(-0.0420), tensor(-0.1395), tensor(0.0443), tensor(0.0141)], 31: [tensor(-0.2071), tensor(-0.0767), tensor(-0.3716), tensor(-0.2855), tensor(-0.0796), tensor(0.0553), tensor(0.0437), tensor(-0.1788), tensor(0.0246), tensor(-0.3831), tensor(-0.1818), tensor(-0.3663), tensor(-0.2030), tensor(-0.2254), tensor(0.0367), tensor(-0.5664), tensor(0.0589), tensor(0.0544), tensor(-0.0066), tensor(-0.1316), tensor(0.0843), tensor(0.0428), tensor(-0.2022), tensor(0.0389), tensor(0.0658), tensor(-0.0378), tensor(0.0770), tensor(0.0623), tensor(0.0680), tensor(0.0866)], 32: [tensor(-0.2074), tensor(0.0575), tensor(0.0384), tensor(0.0485), tensor(0.0578), tensor(-0.2471), tensor(0.0394), tensor(0.0470), tensor(-0.0244), tensor(0.0725), tensor(0.0288), tensor(0.0275), tensor(0.0266), tensor(-0.1562), tensor(0.0735), tensor(-0.3843), tensor(0.0051), tensor(0.0609), tensor(0.0561), tensor(0.0298), tensor(0.0476), tensor(0.0526), tensor(-0.4093), tensor(-0.1450), tensor(0.0588), tensor(0.0343), tensor(0.0205), tensor(-0.2127), tensor(0.0334), tensor(-0.1594)], 33: [tensor(0.0288), tensor(-0.5339), tensor(-0.2304), tensor(-0.0423), tensor(0.0129), tensor(-0.0807), tensor(-0.0163), tensor(-0.2255), tensor(-0.0138), tensor(-0.2520), tensor(0.0013), tensor(-0.1433), tensor(-0.1370), tensor(0.0058), tensor(0.0284), tensor(0.0382), tensor(-0.1646), tensor(-0.3560), tensor(0.0206), tensor(-0.3138), tensor(-0.4535), tensor(-0.0541), tensor(-0.2424), tensor(0.0226), tensor(0.0302), tensor(0.0316), tensor(-0.6079), tensor(-0.2107), tensor(0.0211), tensor(-0.2919)], 34: [tensor(0.0424), tensor(0.0376), tensor(0.0236), tensor(0.0494), tensor(0.0411), tensor(0.0176), tensor(-0.1708), tensor(0.0188), tensor(0.0420), tensor(0.0571), tensor(0.0322), tensor(0.0443), tensor(-0.0723), tensor(0.0524), tensor(0.0342), tensor(0.0761), tensor(0.0729), tensor(0.0082), tensor(0.0415), tensor(0.0192), tensor(0.0736), tensor(0.0454), tensor(0.0459), tensor(0.0432), tensor(-0.4236), tensor(0.0400), tensor(0.0344), tensor(0.0657), tensor(0.0382), tensor(0.0409)], 35: [tensor(0.0113), tensor(0.0440), tensor(0.0652), tensor(-0.4150), tensor(0.0188), tensor(-0.1688), tensor(0.0437), tensor(0.0140), tensor(0.0702), tensor(0.0719), tensor(0.0508), tensor(0.0197), tensor(0.0307), tensor(0.0219), tensor(0.0367), tensor(0.0188), tensor(-0.0121), tensor(0.0569), tensor(0.0228), tensor(0.0776), tensor(0.0327), tensor(0.0624), tensor(-0.4458), tensor(0.0475), tensor(0.0394), tensor(0.0451), tensor(-0.1893), tensor(0.0412), tensor(0.0517), tensor(0.0027)], 36: [tensor(-0.2286), tensor(0.0234), tensor(0.0672), tensor(0.0167), tensor(-0.2183), tensor(0.0731), tensor(0.0207), tensor(0.0869), tensor(-0.2234), tensor(0.0549), tensor(-0.2304), tensor(0.0418), tensor(0.0416), tensor(0.0281), tensor(0.0151), tensor(0.0084), tensor(-0.0894), tensor(-0.1204), tensor(0.0050), tensor(0.0450), tensor(0.0184), tensor(0.0459), tensor(0.0249), tensor(0.0621), tensor(0.0713), tensor(0.0392), tensor(0.0539), tensor(-0.1935), tensor(0.0248), tensor(-0.0102)], 37: [tensor(0.0129), tensor(0.0667), tensor(-0.2633), tensor(0.0768), tensor(0.0406), tensor(-0.0407), tensor(-0.2575), tensor(-0.1746), tensor(0.0408), tensor(0.0788), tensor(0.0320), tensor(0.0381), tensor(0.0472), tensor(0.0627), tensor(0.0511), tensor(-0.1527), tensor(0.0489), tensor(-0.2966), tensor(0.0351), tensor(0.0351), tensor(0.0518), tensor(0.0201), tensor(0.0982), tensor(-0.2086), tensor(0.0138), tensor(0.0283), tensor(0.0469), tensor(0.0838), tensor(0.0528), tensor(0.0529)], 38: [tensor(0.0894), tensor(0.0782), tensor(0.0400), tensor(0.0506), tensor(0.0489), tensor(0.0510), tensor(0.0369), tensor(0.0564), tensor(-0.2303), tensor(-0.2242), tensor(0.0453), tensor(0.0658), tensor(0.0507), tensor(0.0667), tensor(0.0609), tensor(0.0474), tensor(0.0589), tensor(0.0465), tensor(0.0151), tensor(-0.1961), tensor(-0.1714), tensor(0.0555), tensor(0.0513), tensor(0.0337), tensor(0.0715), tensor(0.0684), tensor(0.0188), tensor(0.0354), tensor(0.0518), tensor(-6.4165e-05)], 39: [tensor(-0.0098), tensor(0.0157), tensor(-0.2416), tensor(0.0239), tensor(-0.1828), tensor(0.0355), tensor(0.0485), tensor(-0.2128), tensor(0.0553), tensor(-0.0975), tensor(-0.2242), tensor(-0.1378), tensor(-0.0165), tensor(0.0643), tensor(-0.2112), tensor(-0.1463), tensor(-0.0017), tensor(-0.2583), tensor(0.0231), tensor(0.0648), tensor(0.0183), tensor(0.0221), tensor(-0.5159), tensor(0.0125), tensor(-0.3032), tensor(0.0041), tensor(0.0484), tensor(-0.1280), tensor(0.0447), tensor(0.0348)], 40: [tensor(-0.5690), tensor(-1.1724), tensor(-0.7508), tensor(-0.3471), tensor(-0.3584), tensor(0.0607), tensor(-0.1830), tensor(-0.3392), tensor(-0.6321), tensor(-0.8189), tensor(-0.1537), tensor(-0.4084), tensor(-0.5580), tensor(-0.4265), tensor(-0.2537), tensor(-0.6336), tensor(-0.3000), tensor(-0.4080), tensor(-0.2577), tensor(-0.4696), tensor(-0.4517), tensor(-0.6969), tensor(-0.3219), tensor(-0.1309), tensor(-0.3059), tensor(-0.3693), tensor(-0.7374), tensor(-0.5864), tensor(0.0233), tensor(-0.3710)], 41: [tensor(0.0660), tensor(0.0421), tensor(-0.2048), tensor(0.0656), tensor(0.0138), tensor(-0.4176), tensor(0.0426), tensor(0.0224), tensor(-0.1853), tensor(0.0480), tensor(-0.2017), tensor(0.0358), tensor(0.0296), tensor(0.0403), tensor(-0.1360), tensor(0.0355), tensor(-0.1518), tensor(0.0329), tensor(0.0180), tensor(0.0466), tensor(-0.0026), tensor(0.0775), tensor(0.0007), tensor(-0.0009), tensor(0.0146), tensor(-0.3330), tensor(-0.4672), tensor(0.0576), tensor(-0.1269), tensor(0.0181)], 42: [tensor(0.0218), tensor(0.0598), tensor(-0.1184), tensor(0.0466), tensor(-0.0025), tensor(0.0335), tensor(-0.0015), tensor(0.0624), tensor(0.0210), tensor(0.0411), tensor(-0.2505), tensor(0.0307), tensor(-0.2006), tensor(-0.1725), tensor(0.0483), tensor(0.0254), tensor(0.0465), tensor(0.0525), tensor(0.0310), tensor(-0.0359), tensor(-0.1827), tensor(0.0144), tensor(0.0269), tensor(0.0237), tensor(-0.3767), tensor(0.0231), tensor(-0.1468), tensor(0.0794), tensor(0.0122), tensor(0.0313)], 43: [tensor(-0.4713), tensor(0.0461), tensor(0.0392), tensor(0.0221), tensor(-0.1833), tensor(0.0322), tensor(-0.1437), tensor(0.0461), tensor(0.0480), tensor(0.0459), tensor(0.0480), tensor(0.0598), tensor(0.0022), tensor(0.0699), tensor(0.0500), tensor(0.0751), tensor(0.0421), tensor(0.0769), tensor(0.0399), tensor(0.0216), tensor(0.0593), tensor(0.0843), tensor(-0.1447), tensor(0.0103), tensor(-0.0099), tensor(-0.0252), tensor(-0.0175), tensor(0.0354), tensor(-0.0779), tensor(-0.1959)], 44: [tensor(0.0272), tensor(0.0518), tensor(-0.2036), tensor(-0.1185), tensor(0.0127), tensor(-0.1462), tensor(0.0484), tensor(0.0345), tensor(0.0513), tensor(0.0249), tensor(0.0681), tensor(-0.1448), tensor(0.0314), tensor(0.0384), tensor(-0.4238), tensor(0.0163), tensor(0.0357), tensor(0.0782), tensor(0.0461), tensor(0.0264), tensor(0.0343), tensor(-0.2491), tensor(0.0609), tensor(0.0274), tensor(-0.2086), tensor(0.0179), tensor(0.0397), tensor(0.0514), tensor(-0.1745), tensor(0.0464)], 45: [tensor(0.0670), tensor(-0.2257), tensor(-0.0130), tensor(0.0518), tensor(0.0620), tensor(0.0820), tensor(0.0561), tensor(-0.1626), tensor(-0.2126), tensor(-0.3786), tensor(0.0575), tensor(0.0334), tensor(0.0352), tensor(-0.2322), tensor(0.0756), tensor(-0.1846), tensor(0.0508), tensor(0.0279), tensor(0.1004), tensor(0.0343), tensor(0.0440), tensor(0.0781), tensor(0.0112), tensor(-0.1235), tensor(-0.1291), tensor(0.0411), tensor(0.0458), tensor(-0.2198), tensor(0.0525), tensor(0.0050)], 46: [tensor(-0.2964), tensor(-0.3126), tensor(-0.7798), tensor(-0.2747), tensor(-0.2948), tensor(-0.2298), tensor(-0.5541), tensor(-0.1308), tensor(0.0066), tensor(0.0559), tensor(-0.0353), tensor(-0.0090), tensor(-0.1714), tensor(-0.0485), tensor(-0.3670), tensor(-0.5989), tensor(0.0061), tensor(-0.3415), tensor(-0.7256), tensor(-0.4328), tensor(-0.1879), tensor(0.0486), tensor(-0.3796), tensor(0.0368), tensor(-0.2557), tensor(0.0045), tensor(-0.3988), tensor(-0.6858), tensor(-0.5712), tensor(-0.2519)], 47: [tensor(0.0091), tensor(0.0127), tensor(0.0308), tensor(-0.1194), tensor(-0.1374), tensor(0.0446), tensor(0.0430), tensor(-0.2074), tensor(0.0764), tensor(0.0551), tensor(-0.0577), tensor(-0.0013), tensor(0.0497), tensor(0.0136), tensor(0.0510), tensor(0.0221), tensor(0.0083), tensor(-0.4319), tensor(-0.2033), tensor(-0.5353), tensor(-0.0006), tensor(-0.0143), tensor(0.0102), tensor(-0.0388), tensor(-0.1630), tensor(0.0740), tensor(-0.0199), tensor(0.0102), tensor(0.0124), tensor(0.0064)], 48: [tensor(-0.1938), tensor(0.0396), tensor(0.0132), tensor(-0.0281), tensor(0.0692), tensor(-0.2902), tensor(0.0549), tensor(-0.1694), tensor(-0.2136), tensor(0.0331), tensor(0.0304), tensor(0.0460), tensor(-0.1929), tensor(0.0695), tensor(0.0189), tensor(0.0714), tensor(0.0280), tensor(-0.2194), tensor(-0.1053), tensor(-0.2335), tensor(-0.2105), tensor(-0.1897), tensor(0.0233), tensor(-0.1703), tensor(-0.2001), tensor(-0.1939), tensor(0.0215), tensor(0.0664), tensor(0.0623), tensor(0.0182)], 49: [tensor(-0.0024), tensor(0.0455), tensor(0.0272), tensor(-0.2108), tensor(0.0208), tensor(0.0877), tensor(0.0213), tensor(-0.1656), tensor(-0.2986), tensor(-0.2477), tensor(0.0106), tensor(-0.0069), tensor(-0.2637), tensor(0.0471), tensor(0.0323), tensor(-0.1940), tensor(0.0042), tensor(0.0576), tensor(-0.1875), tensor(-0.2303), tensor(-0.4090), tensor(0.0491), tensor(-0.1637), tensor(0.0431), tensor(-0.1269), tensor(0.0460), tensor(0.0770), tensor(-0.1640), tensor(0.0209), tensor(-0.1973)], 50: [tensor(0.0037), tensor(0.0281), tensor(0.0291), tensor(-0.3773), tensor(-0.1522), tensor(0.0233), tensor(0.0290), tensor(0.0165), tensor(0.0360), tensor(0.0178), tensor(-0.0058), tensor(-0.2430), tensor(0.0454), tensor(0.0385), tensor(0.0298), tensor(0.0181), tensor(-0.2046), tensor(0.0428), tensor(0.0192), tensor(0.0011), tensor(0.0344), tensor(-0.0068), tensor(0.0404), tensor(0.0383), tensor(0.0675), tensor(0.0466), tensor(-0.1644), tensor(-0.1669), tensor(0.0441), tensor(0.0402)], 51: [tensor(0.0797), tensor(-0.5870), tensor(-0.6671), tensor(-0.3337), tensor(-0.7441), tensor(-0.0044), tensor(-0.5524), tensor(-0.2270), tensor(-0.6031), tensor(-0.2106), tensor(-1.1120), tensor(-0.3240), tensor(-0.4601), tensor(-0.5313), tensor(-0.2783), tensor(-0.3221), tensor(-0.6170), tensor(-0.0085), tensor(-0.2267), tensor(-0.5630), tensor(-0.0565), tensor(-0.0469), tensor(-0.0157), tensor(-0.3943), tensor(-0.3249), tensor(0.0627), tensor(-0.4271), tensor(-0.2247), tensor(-0.2411), tensor(-0.7554)], 52: [tensor(-0.3742), tensor(0.0688), tensor(0.0067), tensor(-0.1980), tensor(0.0412), tensor(-0.2546), tensor(0.0961), tensor(0.0162), tensor(0.0462), tensor(0.0417), tensor(0.0436), tensor(0.0117), tensor(0.0261), tensor(0.0523), tensor(0.0455), tensor(0.0277), tensor(-0.1379), tensor(-0.2246), tensor(-0.0308), tensor(0.0477), tensor(0.0287), tensor(-0.3437), tensor(0.0224), tensor(0.0417), tensor(-0.3673), tensor(-0.0096), tensor(0.0117), tensor(0.0725), tensor(0.0749), tensor(-0.0325)], 53: [tensor(0.0410), tensor(-0.0461), tensor(0.0597), tensor(0.0250), tensor(-0.2244), tensor(0.0542), tensor(0.0431), tensor(-0.2198), tensor(0.0284), tensor(0.0163), tensor(0.0063), tensor(-0.2693), tensor(0.0164), tensor(0.0724), tensor(-0.2124), tensor(0.0478), tensor(0.0490), tensor(0.0393), tensor(-0.2171), tensor(0.0212), tensor(-0.1765), tensor(0.0109), tensor(0.0081), tensor(-0.0309), tensor(0.0238), tensor(-0.0156), tensor(0.0262), tensor(0.0053), tensor(-0.4110), tensor(0.0432)], 54: [tensor(0.0106), tensor(-0.1624), tensor(-0.1508), tensor(0.0355), tensor(-0.2310), tensor(-0.0898), tensor(0.0431), tensor(-0.1798), tensor(0.0038), tensor(0.0484), tensor(-0.0468), tensor(-0.3778), tensor(-0.3043), tensor(0.0176), tensor(0.0462), tensor(-0.2131), tensor(0.0258), tensor(-0.0005), tensor(0.0318), tensor(-0.2067), tensor(0.0609), tensor(0.0282), tensor(0.0659), tensor(-0.0056), tensor(-0.1095), tensor(-0.1952), tensor(0.0189), tensor(0.0455), tensor(0.0796), tensor(0.0275)], 55: [tensor(0.0249), tensor(0.0305), tensor(-0.1622), tensor(0.0263), tensor(0.0544), tensor(0.0624), tensor(0.0455), tensor(0.0183), tensor(0.0551), tensor(0.0277), tensor(-0.2198), tensor(0.0155), tensor(0.0311), tensor(0.0815), tensor(0.0737), tensor(-0.2002), tensor(0.0318), tensor(-0.1613), tensor(0.0552), tensor(0.0656), tensor(0.0186), tensor(0.0508), tensor(0.0429), tensor(0.0383), tensor(0.0639), tensor(-0.0209), tensor(0.0065), tensor(0.0107), tensor(0.0513), tensor(0.0727)], 56: [tensor(0.0545), tensor(0.0333), tensor(0.0472), tensor(0.0629), tensor(0.0231), tensor(0.0581), tensor(0.0339), tensor(0.0297), tensor(0.0492), tensor(0.0514), tensor(0.0024), tensor(0.0624), tensor(0.0481), tensor(0.0608), tensor(0.0461), tensor(0.0586), tensor(0.0406), tensor(0.0344), tensor(0.0286), tensor(0.0708), tensor(0.0373), tensor(-0.2210), tensor(0.0292), tensor(-0.1930), tensor(0.0692), tensor(0.0456), tensor(0.0557), tensor(-0.1985), tensor(-0.0086), tensor(0.0291)], 57: [tensor(0.0380), tensor(-0.2477), tensor(0.0639), tensor(0.0176), tensor(0.0075), tensor(-0.2351), tensor(-0.0769), tensor(0.0330), tensor(0.0659), tensor(0.0303), tensor(0.0714), tensor(-0.0053), tensor(0.0016), tensor(0.0187), tensor(0.0146), tensor(0.0207), tensor(-0.2457), tensor(0.0705), tensor(0.0334), tensor(0.0411), tensor(0.0768), tensor(0.0797), tensor(0.0395), tensor(0.0381), tensor(0.0222), tensor(0.0456), tensor(0.0509), tensor(0.0342), tensor(0.0460), tensor(0.0112)], 58: [tensor(-0.3054), tensor(-0.3683), tensor(-0.3683), tensor(-0.1957), tensor(-0.4338), tensor(0.0651), tensor(-0.2383), tensor(-0.6814), tensor(-0.6744), tensor(-0.6363), tensor(-0.4079), tensor(-0.4891), tensor(-0.1726), tensor(-0.4400), tensor(-0.2936), tensor(-0.2635), tensor(0.0463), tensor(-0.2983), tensor(-0.6541), tensor(-0.6370), tensor(-0.0072), tensor(-0.9018), tensor(-0.1879), tensor(-0.3196), tensor(-0.8916), tensor(-0.0025), tensor(-0.7232), tensor(-0.4502), tensor(-0.9629), tensor(0.0618)], 59: [tensor(0.0022), tensor(0.0412), tensor(-0.1085), tensor(-0.1855), tensor(0.0479), tensor(0.0652), tensor(-0.2069), tensor(0.0446), tensor(0.0208), tensor(-0.2170), tensor(-0.2188), tensor(-0.2204), tensor(-0.1497), tensor(-0.1849), tensor(-0.4793), tensor(0.0210), tensor(-0.0150), tensor(0.0120), tensor(0.0408), tensor(-0.2612), tensor(0.0386), tensor(-0.1133), tensor(-0.4261), tensor(-0.4570), tensor(0.0775), tensor(-0.1720), tensor(0.0354), tensor(0.0635), tensor(-0.1939), tensor(-0.1936)], 60: [tensor(0.0563), tensor(0.0413), tensor(0.0210), tensor(0.0476), tensor(0.0653), tensor(0.0528), tensor(0.0002), tensor(-0.0146), tensor(0.0535), tensor(0.0064), tensor(0.0464), tensor(0.0024), tensor(0.0364), tensor(0.0217), tensor(0.0715), tensor(0.0344), tensor(-0.0012), tensor(0.0661), tensor(-0.0214), tensor(0.0455), tensor(0.0176), tensor(0.0166), tensor(0.0356), tensor(0.0134), tensor(0.0418), tensor(0.0579), tensor(0.0469), tensor(0.0293), tensor(0.0466), tensor(-0.0321)], 61: [tensor(0.0322), tensor(0.0196), tensor(0.0472), tensor(0.0690), tensor(0.0169), tensor(0.0062), tensor(0.0516), tensor(0.0586), tensor(-0.2270), tensor(-0.2849), tensor(0.0055), tensor(0.0244), tensor(0.0321), tensor(0.0513), tensor(0.0808), tensor(0.0553), tensor(0.0201), tensor(-0.2556), tensor(0.1112), tensor(-0.2821), tensor(-0.0090), tensor(0.0257), tensor(-0.2045), tensor(-0.2315), tensor(0.0258), tensor(0.0078), tensor(0.0638), tensor(0.0565), tensor(0.0189), tensor(0.0427)], 62: [tensor(-0.2481), tensor(0.0636), tensor(-0.1794), tensor(0.0011), tensor(0.0393), tensor(0.0138), tensor(-0.0075), tensor(0.0559), tensor(0.0107), tensor(0.0883), tensor(-0.1367), tensor(0.0490), tensor(0.0655), tensor(-0.2791), tensor(0.0172), tensor(-0.1962), tensor(-0.1967), tensor(0.0046), tensor(-0.4321), tensor(-0.5076), tensor(-0.1612), tensor(-0.1835), tensor(-0.2116), tensor(-0.2754), tensor(-0.0858), tensor(0.0286), tensor(-0.0275), tensor(-0.1826), tensor(-0.2268), tensor(0.0031)], 63: [tensor(0.0472), tensor(0.0559), tensor(0.0212), tensor(0.0426), tensor(-0.2091), tensor(-0.0149), tensor(0.0140), tensor(-0.3097), tensor(-0.0031), tensor(0.0202), tensor(0.0100), tensor(-0.0349), tensor(-0.2907), tensor(0.0213), tensor(-0.2473), tensor(0.0181), tensor(-0.4145), tensor(0.0027), tensor(0.0671), tensor(-0.2186), tensor(0.0221), tensor(-0.2836), tensor(-0.1901), tensor(-0.1758), tensor(0.0269), tensor(0.0565), tensor(-0.1810), tensor(-0.1360), tensor(-0.4967), tensor(0.0515)], 64: [tensor(0.0448), tensor(-0.1030), tensor(-0.2368), tensor(0.0298), tensor(0.0424), tensor(0.0347), tensor(0.0333), tensor(-0.4442), tensor(-0.2048), tensor(0.0018), tensor(-0.1517), tensor(0.0100), tensor(-0.1874), tensor(0.0084), tensor(0.0057), tensor(0.0267), tensor(-0.5011), tensor(0.0686), tensor(-0.0327), tensor(0.0038), tensor(0.0161), tensor(0.0281), tensor(-0.2590), tensor(-0.2390), tensor(0.0107), tensor(-0.0007), tensor(0.0238), tensor(0.0321), tensor(-0.2240), tensor(0.0671)], 65: [tensor(-0.7357), tensor(-0.9735), tensor(-0.6840), tensor(-0.6864), tensor(-0.9593), tensor(-1.1115), tensor(-0.8378), tensor(-0.7139), tensor(-0.1197), tensor(-0.8339), tensor(-0.7014), tensor(-0.6043), tensor(-0.3592), tensor(-0.8962), tensor(-0.6064), tensor(-0.8699), tensor(-0.3810), tensor(-0.6631), tensor(-0.4425), tensor(-1.2165), tensor(-0.3569), tensor(-0.3537), tensor(-0.4528), tensor(-0.4574), tensor(-0.9066), tensor(-1.0320), tensor(-1.2222), tensor(-0.8694), tensor(-0.5830), tensor(-0.3847)], 66: [tensor(0.0056), tensor(-0.0031), tensor(-0.1548), tensor(-0.1957), tensor(-0.2272), tensor(0.0771), tensor(-0.2808), tensor(-0.1725), tensor(0.0144), tensor(0.0219), tensor(-0.0062), tensor(-0.2134), tensor(0.0706), tensor(0.0636), tensor(0.0734), tensor(0.0457), tensor(-0.1997), tensor(-0.0199), tensor(-0.1850), tensor(0.0231), tensor(0.0164), tensor(0.0555), tensor(0.0150), tensor(0.0832), tensor(-0.2118), tensor(-0.2504), tensor(0.0515), tensor(0.0666), tensor(0.0398), tensor(0.0251)], 67: [tensor(-0.6462), tensor(0.0944), tensor(-0.4157), tensor(0.0819), tensor(-0.6424), tensor(-0.1254), tensor(-0.5162), tensor(0.0361), tensor(-0.3199), tensor(-0.5550), tensor(-0.3938), tensor(-0.0439), tensor(-0.5191), tensor(0.0467), tensor(-0.2114), tensor(0.0212), tensor(0.0411), tensor(-0.3753), tensor(-0.5186), tensor(-0.7316), tensor(-0.8563), tensor(0.0135), tensor(-0.4782), tensor(-0.1876), tensor(-0.0880), tensor(-0.1605), tensor(-0.2802), tensor(-0.1771), tensor(-0.3037), tensor(0.0110)], 68: [tensor(0.0653), tensor(-0.0121), tensor(0.0285), tensor(0.0323), tensor(0.0109), tensor(0.0427), tensor(-0.2280), tensor(-0.1981), tensor(0.0346), tensor(-0.2752), tensor(0.0312), tensor(0.0073), tensor(0.0791), tensor(-0.0324), tensor(-0.2861), tensor(-0.4926), tensor(0.0461), tensor(-0.1225), tensor(-0.2289), tensor(-0.2846), tensor(0.0454), tensor(0.0638), tensor(-0.5606), tensor(-0.1895), tensor(-0.0121), tensor(0.0265), tensor(-0.3947), tensor(-0.2214), tensor(0.0492), tensor(-0.0161)], 69: [tensor(0.0477), tensor(-0.2335), tensor(-0.0355), tensor(-0.2038), tensor(0.0348), tensor(0.0528), tensor(-0.4935), tensor(-0.1413), tensor(0.0399), tensor(-0.2327), tensor(-0.3231), tensor(-0.1751), tensor(-0.1828), tensor(-0.3511), tensor(-0.2692), tensor(-0.0235), tensor(-0.2307), tensor(-0.1352), tensor(-0.6062), tensor(-0.2028), tensor(0.0056), tensor(-0.2732), tensor(-0.0962), tensor(0.0344), tensor(-0.3066), tensor(-0.4843), tensor(-0.2223), tensor(-0.0327), tensor(0.0554), tensor(-0.2132)], 70: [tensor(-0.2147), tensor(-0.7104), tensor(0.0331), tensor(0.0553), tensor(0.0727), tensor(-0.1811), tensor(-0.3796), tensor(-0.3080), tensor(-0.1203), tensor(-0.6534), tensor(-0.1343), tensor(-0.3951), tensor(-0.0088), tensor(-0.3115), tensor(-0.2167), tensor(-0.4622), tensor(-0.4083), tensor(-0.2406), tensor(0.0578), tensor(-0.3314), tensor(-0.1335), tensor(-1.0097), tensor(0.0225), tensor(-0.6049), tensor(0.0690), tensor(-0.3871), tensor(0.0131), tensor(-0.1731), tensor(-0.2448), tensor(-0.3085)], 71: [tensor(0.0697), tensor(0.0437), tensor(-0.3662), tensor(0.0454), tensor(0.0527), tensor(-0.2208), tensor(-0.2268), tensor(0.0915), tensor(-0.1970), tensor(0.0398), tensor(0.0107), tensor(0.0790), tensor(0.0049), tensor(0.0505), tensor(0.0399), tensor(0.0308), tensor(0.0324), tensor(0.0413), tensor(0.0322), tensor(-0.0189), tensor(0.0256), tensor(-0.4093), tensor(0.0676), tensor(0.0598), tensor(-0.2381), tensor(0.0487), tensor(0.0957), tensor(0.0483), tensor(0.0431), tensor(-0.1735)], 72: [tensor(-0.1388), tensor(-0.2098), tensor(-0.1704), tensor(0.0525), tensor(0.0159), tensor(0.0333), tensor(0.0485), tensor(0.0362), tensor(0.0357), tensor(-0.1570), tensor(0.0799), tensor(0.0449), tensor(0.0290), tensor(0.0724), tensor(-0.0078), tensor(0.0082), tensor(-0.1609), tensor(-0.1080), tensor(0.0609), tensor(0.0119), tensor(-0.1841), tensor(-0.2329), tensor(0.0568), tensor(0.0799), tensor(0.0758), tensor(-0.4607), tensor(-0.0311), tensor(0.0198), tensor(-0.1682), tensor(0.0267)], 73: [tensor(-0.3831), tensor(-0.2245), tensor(-0.1964), tensor(0.0421), tensor(-0.5256), tensor(-0.1831), tensor(-0.4817), tensor(-0.2428), tensor(-0.0020), tensor(-0.1447), tensor(-0.0097), tensor(-0.3145), tensor(0.0495), tensor(-0.0142), tensor(-0.2314), tensor(0.0691), tensor(0.0609), tensor(-0.2086), tensor(-0.1041), tensor(0.0479), tensor(0.0057), tensor(-0.0382), tensor(-0.3061), tensor(-0.2942), tensor(-0.0472), tensor(-0.1565), tensor(-0.1898), tensor(-0.1649), tensor(-0.1711), tensor(-0.2497)], 74: [tensor(-0.2132), tensor(-0.0117), tensor(0.0440), tensor(-0.3865), tensor(0.0164), tensor(-0.0118), tensor(-0.2474), tensor(-0.0481), tensor(0.0746), tensor(-0.1675), tensor(0.0625), tensor(-0.3444), tensor(-0.3076), tensor(0.0762), tensor(0.0019), tensor(-0.0558), tensor(0.0449), tensor(0.0227), tensor(0.0155), tensor(-0.2006), tensor(0.0340), tensor(0.0368), tensor(-0.1465), tensor(0.0239), tensor(0.0741), tensor(-0.1975), tensor(-0.3021), tensor(0.0342), tensor(-0.1836), tensor(0.0569)], 75: [tensor(-0.3123), tensor(0.0250), tensor(-0.4546), tensor(-0.2663), tensor(-0.2172), tensor(-0.7530), tensor(-0.2011), tensor(-0.2662), tensor(-0.0901), tensor(-0.0756), tensor(-0.4204), tensor(-0.4875), tensor(-0.4109), tensor(0.0027), tensor(0.0701), tensor(0.0673), tensor(-0.2272), tensor(-0.0424), tensor(-0.1712), tensor(-0.5531), tensor(-0.3422), tensor(-0.2967), tensor(-0.7202), tensor(0.0458), tensor(-0.4778), tensor(-0.3581), tensor(-0.4320), tensor(-0.6333), tensor(-0.1853), tensor(-0.2710)], 76: [tensor(0.0697), tensor(0.0202), tensor(0.0362), tensor(-0.3639), tensor(0.0168), tensor(-0.0215), tensor(0.0252), tensor(-0.2739), tensor(-0.1401), tensor(0.0172), tensor(0.0258), tensor(0.0211), tensor(0.0477), tensor(-0.1083), tensor(0.0264), tensor(0.0457), tensor(-0.1405), tensor(0.0069), tensor(-0.2679), tensor(0.0181), tensor(-0.1665), tensor(0.0661), tensor(-0.1946), tensor(0.0242), tensor(0.0306), tensor(0.0541), tensor(0.0582), tensor(0.0714), tensor(-0.4091), tensor(-0.2075)], 77: [tensor(-0.5300), tensor(0.0591), tensor(0.0251), tensor(-0.1967), tensor(0.0369), tensor(-0.2289), tensor(0.0167), tensor(0.0309), tensor(0.0002), tensor(0.0436), tensor(-0.2751), tensor(-0.2241), tensor(0.0286), tensor(0.0156), tensor(0.0486), tensor(0.0220), tensor(-0.1998), tensor(-0.0073), tensor(-0.1681), tensor(-0.0434), tensor(0.0384), tensor(-0.2525), tensor(0.0483), tensor(-0.1565), tensor(0.0326), tensor(-0.1210), tensor(0.0595), tensor(0.0432), tensor(-0.1887), tensor(0.0644)], 78: [tensor(-0.2590), tensor(-0.5657), tensor(-0.3136), tensor(-0.4300), tensor(0.0252), tensor(0.0674), tensor(-0.1871), tensor(-0.5346), tensor(-0.2564), tensor(0.0535), tensor(-0.0048), tensor(0.0302), tensor(0.0482), tensor(-0.2865), tensor(-0.4030), tensor(-0.3956), tensor(-0.3063), tensor(-0.2439), tensor(-0.6911), tensor(-0.1745), tensor(-0.1981), tensor(-0.0317), tensor(-0.1837), tensor(0.0154), tensor(-0.0293), tensor(-0.2908), tensor(-0.1991), tensor(-0.1174), tensor(-0.5206), tensor(-0.1997)], 79: [tensor(0.0511), tensor(-0.1636), tensor(0.0541), tensor(0.0226), tensor(0.0422), tensor(-0.1791), tensor(0.0789), tensor(-0.0121), tensor(-0.4359), tensor(-0.0353), tensor(-0.2103), tensor(0.0484), tensor(0.0280), tensor(0.0394), tensor(0.0432), tensor(-0.2472), tensor(0.0634), tensor(0.0349), tensor(0.0461), tensor(0.0486), tensor(0.0182), tensor(-0.5301), tensor(0.0565), tensor(-0.2511), tensor(-0.0241), tensor(-0.2309), tensor(-0.2665), tensor(0.0467), tensor(-0.1792), tensor(-0.1415)], 80: [tensor(-0.2444), tensor(-0.2028), tensor(0.0610), tensor(0.0497), tensor(0.0446), tensor(0.0703), tensor(0.0288), tensor(0.0642), tensor(0.0819), tensor(0.0445), tensor(0.0112), tensor(0.0679), tensor(-0.1672), tensor(-0.1291), tensor(-0.2920), tensor(-0.2233), tensor(0.0480), tensor(-0.0007), tensor(0.0295), tensor(-0.1394), tensor(-0.4929), tensor(-0.0456), tensor(0.0747), tensor(-0.2221), tensor(-0.0328), tensor(0.0052), tensor(0.0726), tensor(0.0401), tensor(-0.0123), tensor(0.0373)], 81: [tensor(0.0162), tensor(0.0692), tensor(0.0450), tensor(0.0805), tensor(0.0252), tensor(0.0549), tensor(0.0365), tensor(0.0481), tensor(-0.2203), tensor(0.0481), tensor(0.0193), tensor(-0.2112), tensor(0.0309), tensor(0.0565), tensor(-0.1077), tensor(-0.3280), tensor(0.0417), tensor(0.0508), tensor(0.0496), tensor(0.0279), tensor(0.0521), tensor(0.0589), tensor(0.0417), tensor(0.0338), tensor(-0.1891), tensor(-0.3912), tensor(0.0317), tensor(-0.1553), tensor(-0.0071), tensor(-0.2352)], 82: [tensor(-0.0139), tensor(-0.2266), tensor(-0.1921), tensor(0.0436), tensor(0.0475), tensor(-0.0314), tensor(-0.2245), tensor(-0.4448), tensor(0.0236), tensor(-0.3524), tensor(-0.0231), tensor(0.0532), tensor(-0.2359), tensor(-0.2201), tensor(-0.0446), tensor(0.0240), tensor(-0.1646), tensor(0.0363), tensor(0.0099), tensor(0.0252), tensor(-0.0599), tensor(-0.3008), tensor(-0.0075), tensor(-0.3200), tensor(0.0573), tensor(0.0456), tensor(-0.1899), tensor(0.0321), tensor(0.0432), tensor(-0.5168)], 83: [tensor(-0.0012), tensor(0.0471), tensor(-0.0003), tensor(-0.2837), tensor(0.0390), tensor(-0.4483), tensor(-0.2280), tensor(-0.0242), tensor(0.0530), tensor(-0.1734), tensor(-0.2916), tensor(-0.5644), tensor(-0.1473), tensor(-0.1999), tensor(-0.2248), tensor(0.0328), tensor(0.0768), tensor(-0.1932), tensor(-0.1954), tensor(0.0170), tensor(0.0004), tensor(-0.1197), tensor(0.0064), tensor(-0.0225), tensor(-0.1922), tensor(0.0143), tensor(0.0180), tensor(-0.1993), tensor(0.0365), tensor(0.0855)], 84: [tensor(0.0403), tensor(-0.0146), tensor(-0.0213), tensor(-0.2522), tensor(0.0350), tensor(-0.1852), tensor(-0.0177), tensor(0.0091), tensor(0.0056), tensor(-0.1852), tensor(0.0956), tensor(-0.2115), tensor(-0.3500), tensor(-0.3550), tensor(-0.2924), tensor(0.0865), tensor(0.0212), tensor(0.0848), tensor(-0.1629), tensor(0.0385), tensor(-0.3856), tensor(-0.3382), tensor(-0.4712), tensor(-0.1138), tensor(-0.7895), tensor(-0.2676), tensor(0.0437), tensor(-0.3995), tensor(-0.3877), tensor(-0.3896)], 85: [tensor(-0.1359), tensor(0.0545), tensor(0.0224), tensor(0.0341), tensor(0.0684), tensor(0.0634), tensor(-0.0289), tensor(-0.1678), tensor(-0.1625), tensor(0.0268), tensor(0.0403), tensor(0.0855), tensor(-0.0264), tensor(0.0422), tensor(-0.2292), tensor(-0.1699), tensor(0.0545), tensor(0.0082), tensor(0.0538), tensor(0.0405), tensor(0.0209), tensor(-0.0195), tensor(0.0678), tensor(0.0271), tensor(0.0408), tensor(0.0530), tensor(0.0605), tensor(-0.0101), tensor(0.0494), tensor(0.0373)], 86: [tensor(-0.1342), tensor(-0.2926), tensor(0.0186), tensor(-0.0240), tensor(-0.4842), tensor(-0.3364), tensor(-0.2394), tensor(-0.3122), tensor(-1.1320), tensor(-0.5023), tensor(-0.0236), tensor(-0.7111), tensor(-0.4089), tensor(-0.0358), tensor(-0.4556), tensor(-0.2685), tensor(0.0510), tensor(-0.1659), tensor(-0.2793), tensor(-0.0092), tensor(-0.9632), tensor(0.0434), tensor(-0.2214), tensor(-0.0195), tensor(-0.5087), tensor(-0.1705), tensor(-0.1294), tensor(-0.4325), tensor(-0.6824), tensor(-0.2358)], 87: [tensor(0.0018), tensor(0.0434), tensor(-0.1862), tensor(0.0368), tensor(-0.0617), tensor(-0.0208), tensor(-0.0081), tensor(-0.2325), tensor(0.0490), tensor(-0.3057), tensor(0.0170), tensor(-0.4094), tensor(-0.3592), tensor(0.0330), tensor(-0.3276), tensor(0.0571), tensor(-0.2405), tensor(0.0066), tensor(-0.2164), tensor(0.0644), tensor(-0.2034), tensor(-0.1749), tensor(-0.0385), tensor(0.0396), tensor(0.0378), tensor(0.0997), tensor(-0.3181), tensor(-0.2224), tensor(-0.2257), tensor(0.0982)], 88: [tensor(-0.1732), tensor(-0.1480), tensor(0.0334), tensor(0.0680), tensor(-0.2698), tensor(-0.2387), tensor(0.0504), tensor(0.0512), tensor(0.0213), tensor(0.0916), tensor(0.0592), tensor(0.0115), tensor(0.0612), tensor(0.0766), tensor(-0.1840), tensor(0.0698), tensor(0.0255), tensor(0.0358), tensor(0.0371), tensor(0.0766), tensor(-0.0016), tensor(0.0410), tensor(0.0721), tensor(0.0428), tensor(0.0496), tensor(-0.2052), tensor(0.0339), tensor(-0.0162), tensor(-0.0080), tensor(0.0342)], 89: [tensor(0.0134), tensor(-0.0522), tensor(-0.2421), tensor(-0.0050), tensor(0.0266), tensor(0.0215), tensor(0.0404), tensor(0.0166), tensor(0.0269), tensor(-0.1906), tensor(0.0439), tensor(0.0173), tensor(-0.0181), tensor(-0.3217), tensor(0.0447), tensor(0.0954), tensor(-0.1906), tensor(0.0257), tensor(-0.4248), tensor(-0.4834), tensor(0.0668), tensor(0.0793), tensor(-0.3013), tensor(0.0614), tensor(-0.2265), tensor(0.0598), tensor(-0.2879), tensor(0.0047), tensor(0.0670), tensor(0.0361)], 90: [tensor(-0.8101), tensor(-0.9715), tensor(-0.7674), tensor(-0.2855), tensor(0.0522), tensor(-0.0414), tensor(-0.8845), tensor(-0.4019), tensor(-0.1953), tensor(-0.2735), tensor(-0.4267), tensor(-0.8579), tensor(-0.6139), tensor(-0.5718), tensor(-0.2010), tensor(-0.0404), tensor(-0.1236), tensor(-0.3569), tensor(-0.3856), tensor(-0.3799), tensor(-0.2222), tensor(-0.3555), tensor(-0.5963), tensor(-0.4622), tensor(0.0064), tensor(-0.4269), tensor(-0.6602), tensor(-0.8221), tensor(0.0996), tensor(-0.2432)], 91: [tensor(-0.1613), tensor(0.0754), tensor(-0.2638), tensor(-0.0455), tensor(0.0349), tensor(-0.2772), tensor(-0.4455), tensor(-0.2442), tensor(-0.3014), tensor(0.0194), tensor(-0.2074), tensor(-0.3981), tensor(-0.1924), tensor(-0.2140), tensor(-0.6302), tensor(-0.0725), tensor(-0.2465), tensor(-0.2245), tensor(0.0018), tensor(-0.0977), tensor(-0.4075), tensor(-0.2635), tensor(0.0339), tensor(-0.8720), tensor(0.0499), tensor(-0.0695), tensor(0.0172), tensor(-0.0783), tensor(-0.2210), tensor(-0.0875)], 92: [tensor(0.0381), tensor(0.0557), tensor(0.0299), tensor(0.0528), tensor(0.0690), tensor(0.0451), tensor(0.0525), tensor(0.0509), tensor(0.0539), tensor(0.0341), tensor(0.0547), tensor(0.0432), tensor(0.0505), tensor(0.0350), tensor(0.0010), tensor(0.0264), tensor(0.0199), tensor(-0.1683), tensor(0.0368), tensor(0.0408), tensor(0.0397), tensor(-0.1761), tensor(-0.1653), tensor(0.0382), tensor(0.0284), tensor(0.0056), tensor(-0.2375), tensor(0.0320), tensor(0.0387), tensor(0.0632)], 93: [tensor(0.0696), tensor(0.0611), tensor(0.0316), tensor(0.0407), tensor(0.0210), tensor(0.0191), tensor(0.0428), tensor(-0.1358), tensor(-0.0215), tensor(-0.1560), tensor(-0.1966), tensor(0.0649), tensor(0.0676), tensor(0.0250), tensor(-0.1222), tensor(-0.3033), tensor(-0.1756), tensor(0.0083), tensor(0.0561), tensor(0.0715), tensor(0.0560), tensor(0.0522), tensor(-0.1845), tensor(-0.2090), tensor(-0.0154), tensor(0.0139), tensor(-0.0204), tensor(0.0626), tensor(0.0101), tensor(-0.2076)], 94: [tensor(-0.1879), tensor(-0.2885), tensor(-0.1933), tensor(-0.0036), tensor(-0.4657), tensor(-0.4750), tensor(0.0189), tensor(-0.2188), tensor(-0.1574), tensor(0.0197), tensor(-0.5034), tensor(-0.6158), tensor(-0.6000), tensor(-0.2349), tensor(0.0354), tensor(0.0204), tensor(-0.4850), tensor(-0.5988), tensor(-0.3773), tensor(-0.3576), tensor(-0.1883), tensor(0.0509), tensor(-0.7624), tensor(-0.1785), tensor(-0.2011), tensor(-0.0203), tensor(-0.4798), tensor(-0.2157), tensor(0.0330), tensor(-0.2893)], 95: [tensor(0.0886), tensor(0.0206), tensor(0.0240), tensor(0.0392), tensor(-0.1810), tensor(0.0565), tensor(0.0452), tensor(-0.0415), tensor(0.0332), tensor(-0.2135), tensor(0.0690), tensor(0.0280), tensor(0.0487), tensor(-0.1115), tensor(0.0040), tensor(0.0168), tensor(0.0231), tensor(-0.2815), tensor(-0.2060), tensor(-0.0293), tensor(0.0607), tensor(0.0436), tensor(0.0281), tensor(-0.2060), tensor(-0.2399), tensor(0.0427), tensor(0.0319), tensor(0.0397), tensor(0.0047), tensor(-0.1787)], 96: [tensor(0.0457), tensor(-0.2107), tensor(-7.2867e-05), tensor(0.0340), tensor(0.0330), tensor(0.0368), tensor(-0.0032), tensor(-0.4929), tensor(0.0373), tensor(0.0150), tensor(0.0785), tensor(0.0186), tensor(0.0864), tensor(0.0402), tensor(-0.0162), tensor(0.0150), tensor(-0.1883), tensor(0.0584), tensor(0.0217), tensor(0.0528), tensor(0.0424), tensor(0.0550), tensor(0.0978), tensor(0.0274), tensor(0.0352), tensor(-0.2132), tensor(0.0599), tensor(0.0607), tensor(0.0527), tensor(-0.0177)], 97: [tensor(0.0031), tensor(0.0399), tensor(0.0339), tensor(0.0446), tensor(-0.1780), tensor(-0.2513), tensor(-0.2126), tensor(-0.2487), tensor(-0.1547), tensor(0.0336), tensor(0.0477), tensor(-0.1558), tensor(-0.0020), tensor(0.0336), tensor(-0.1691), tensor(0.0676), tensor(0.0407), tensor(0.0492), tensor(0.0391), tensor(0.0400), tensor(0.0288), tensor(-0.1611), tensor(0.0119), tensor(0.0747), tensor(0.0645), tensor(0.0049), tensor(-0.0094), tensor(-0.2173), tensor(0.0448), tensor(-0.1762)], 98: [tensor(0.0328), tensor(0.0493), tensor(0.0286), tensor(0.0434), tensor(0.0344), tensor(0.0370), tensor(0.0391), tensor(0.0717), tensor(-0.1208), tensor(0.0494), tensor(0.0206), tensor(0.0420), tensor(-0.0236), tensor(0.0345), tensor(0.0812), tensor(0.0238), tensor(-0.1842), tensor(-0.1209), tensor(0.0865), tensor(0.0426), tensor(0.0365), tensor(-0.1308), tensor(0.0807), tensor(0.0277), tensor(0.0414), tensor(0.0208), tensor(0.0700), tensor(0.0176), tensor(-0.1783), tensor(-0.2142)], 99: [tensor(-0.1512), tensor(-0.1806), tensor(-0.4483), tensor(-0.3830), tensor(-0.3379), tensor(-0.2063), tensor(0.0379), tensor(0.0056), tensor(0.0245), tensor(-0.2459), tensor(-0.1301), tensor(-0.4348), tensor(-0.5087), tensor(-0.2413), tensor(-0.4339), tensor(-0.4617), tensor(0.0354), tensor(-0.3276), tensor(0.0820), tensor(0.0643), tensor(-0.2366), tensor(0.0253), tensor(-0.2402), tensor(0.0048), tensor(-0.2123), tensor(0.0352), tensor(-0.1537), tensor(-0.2185), tensor(-0.1222), tensor(0.0136)], 100: [tensor(-0.3565), tensor(0.0919), tensor(0.0464), tensor(-0.2543), tensor(0.0405), tensor(-0.4095), tensor(0.0804), tensor(0.0114), tensor(-0.2541), tensor(0.0467), tensor(0.0494), tensor(-0.0759), tensor(-0.0805), tensor(0.0546), tensor(0.0661), tensor(-0.2003), tensor(-0.0071), tensor(0.0671), tensor(0.0312), tensor(0.0554), tensor(0.0326), tensor(0.0649), tensor(0.0503), tensor(0.0265), tensor(-0.0126), tensor(0.0330), tensor(-0.2557), tensor(0.0408), tensor(0.0817), tensor(-0.0053)], 101: [tensor(0.0327), tensor(0.0270), tensor(-0.2923), tensor(0.0165), tensor(0.0485), tensor(-0.1809), tensor(0.0606), tensor(0.0808), tensor(0.0052), tensor(0.0622), tensor(0.0449), tensor(0.0580), tensor(0.0760), tensor(0.0646), tensor(0.0642), tensor(-0.0079), tensor(0.0453), tensor(0.0105), tensor(0.0444), tensor(0.0239), tensor(0.0187), tensor(0.0645), tensor(0.0268), tensor(0.0337), tensor(0.0583), tensor(0.0392), tensor(0.0650), tensor(0.0511), tensor(0.0467), tensor(0.0100)], 102: [tensor(0.0185), tensor(-0.0289), tensor(0.0496), tensor(-0.1834), tensor(-0.1914), tensor(-0.2347), tensor(-0.0279), tensor(-0.1847), tensor(-0.1695), tensor(-0.3339), tensor(-0.1571), tensor(-0.4166), tensor(0.0330), tensor(-0.1718), tensor(-0.1413), tensor(0.0537), tensor(0.0084), tensor(0.0538), tensor(0.0463), tensor(-0.4222), tensor(0.0415), tensor(0.0516), tensor(-0.1078), tensor(-0.2221), tensor(-0.2397), tensor(-0.1808), tensor(0.0321), tensor(0.0536), tensor(-0.3832), tensor(0.0393)], 103: [tensor(0.0068), tensor(0.0705), tensor(0.0696), tensor(0.0262), tensor(-0.0031), tensor(0.0315), tensor(-0.1180), tensor(0.0855), tensor(-0.1528), tensor(-0.2118), tensor(0.0309), tensor(0.0422), tensor(0.0319), tensor(-0.4345), tensor(0.0277), tensor(-0.0101), tensor(-0.1969), tensor(0.0462), tensor(0.0460), tensor(0.0802), tensor(0.0551), tensor(0.0465), tensor(0.0301), tensor(0.0017), tensor(0.0573), tensor(-0.2414), tensor(-0.2499), tensor(0.0310), tensor(-0.0319), tensor(0.0659)], 104: [tensor(-0.0049), tensor(0.0438), tensor(0.0390), tensor(-0.2357), tensor(0.0386), tensor(-0.1490), tensor(0.0147), tensor(0.0311), tensor(0.0674), tensor(-0.1050), tensor(0.0381), tensor(-0.0132), tensor(-0.0041), tensor(0.0371), tensor(0.0395), tensor(-0.0048), tensor(0.0453), tensor(0.0302), tensor(-0.4188), tensor(0.0076), tensor(0.0507), tensor(0.0397), tensor(-0.1740), tensor(0.0221), tensor(-0.0285), tensor(0.0302), tensor(-0.1961), tensor(0.0574), tensor(-0.0008), tensor(0.0374)], 105: [tensor(-0.1838), tensor(-0.1999), tensor(-0.2086), tensor(-0.1311), tensor(0.0698), tensor(0.0271), tensor(0.0482), tensor(0.0496), tensor(0.0080), tensor(-0.1959), tensor(-0.1017), tensor(0.0528), tensor(0.0319), tensor(0.0552), tensor(0.0560), tensor(0.0648), tensor(0.0367), tensor(0.0582), tensor(0.0130), tensor(0.0305), tensor(0.0156), tensor(-0.2421), tensor(-0.1913), tensor(0.0422), tensor(-0.2021), tensor(0.0214), tensor(-0.2474), tensor(0.0587), tensor(-0.1970), tensor(0.0386)], 106: [tensor(0.0626), tensor(0.0139), tensor(-0.1838), tensor(0.0423), tensor(-0.0156), tensor(-0.0681), tensor(0.0524), tensor(-0.4457), tensor(0.0620), tensor(0.0585), tensor(0.0483), tensor(-0.2603), tensor(0.0521), tensor(-0.2450), tensor(-0.0229), tensor(-0.2193), tensor(0.0277), tensor(0.0603), tensor(0.0661), tensor(0.0768), tensor(-0.3638), tensor(-0.1824), tensor(0.0503), tensor(0.0138), tensor(0.0774), tensor(0.0337), tensor(-0.1934), tensor(-0.2352), tensor(-0.1490), tensor(-0.2484)], 107: [tensor(0.0533), tensor(0.0410), tensor(-0.0078), tensor(0.0775), tensor(-0.1036), tensor(-0.2507), tensor(0.0547), tensor(-0.0359), tensor(0.0225), tensor(0.0215), tensor(0.0240), tensor(0.0258), tensor(-0.0127), tensor(0.0263), tensor(0.0419), tensor(0.0653), tensor(0.0386), tensor(0.0446), tensor(-0.0057), tensor(-0.1189), tensor(0.0624), tensor(0.0671), tensor(0.0231), tensor(0.0806), tensor(0.0251), tensor(0.0282), tensor(0.0249), tensor(0.0293), tensor(0.0497), tensor(0.0456)], 108: [tensor(0.0297), tensor(0.0306), tensor(0.0166), tensor(0.0601), tensor(-0.0036), tensor(0.1090), tensor(0.0406), tensor(-0.1249), tensor(0.0649), tensor(0.0631), tensor(0.0778), tensor(-0.2129), tensor(0.0162), tensor(0.0604), tensor(0.0778), tensor(-0.0517), tensor(0.0532), tensor(0.0426), tensor(-0.0175), tensor(0.0246), tensor(0.0736), tensor(0.0429), tensor(0.0429), tensor(0.0704), tensor(-0.1764), tensor(-0.0060), tensor(0.0161), tensor(-0.2160), tensor(0.0195), tensor(-0.0144)], 109: [tensor(0.0343), tensor(0.0338), tensor(-0.1992), tensor(-0.2202), tensor(-0.0094), tensor(0.0523), tensor(0.0242), tensor(0.0732), tensor(0.0338), tensor(-0.1740), tensor(-0.1881), tensor(0.0685), tensor(0.0394), tensor(0.0687), tensor(0.0374), tensor(0.0403), tensor(0.0350), tensor(0.0308), tensor(0.0141), tensor(-0.1760), tensor(0.0472), tensor(0.0461), tensor(0.0379), tensor(0.0561), tensor(0.0252), tensor(0.0652), tensor(0.0364), tensor(0.0106), tensor(0.0359), tensor(-0.0009)], 110: [tensor(0.0757), tensor(0.0808), tensor(0.0324), tensor(0.0652), tensor(0.0477), tensor(0.0602), tensor(0.0060), tensor(0.0545), tensor(0.0661), tensor(0.0590), tensor(-0.0088), tensor(0.0471), tensor(-0.0191), tensor(0.0378), tensor(0.0240), tensor(0.0273), tensor(-0.0098), tensor(0.0571), tensor(0.0012), tensor(0.0271), tensor(0.0405), tensor(0.0079), tensor(0.0827), tensor(0.0332), tensor(0.0261), tensor(-0.2059), tensor(0.0671), tensor(0.0393), tensor(-0.2070), tensor(0.0012)], 111: [tensor(0.0265), tensor(0.0274), tensor(-0.2287), tensor(-0.3765), tensor(-0.0020), tensor(0.0635), tensor(-0.2671), tensor(0.0591), tensor(0.0335), tensor(0.0835), tensor(0.0146), tensor(-0.3955), tensor(-0.2217), tensor(-0.3455), tensor(0.0513), tensor(0.0625), tensor(-0.1495), tensor(0.0673), tensor(0.0466), tensor(-0.1902), tensor(0.0400), tensor(0.0360), tensor(-0.1969), tensor(-0.4050), tensor(0.0493), tensor(0.0225), tensor(0.0425), tensor(0.0369), tensor(0.0646), tensor(-0.1929)], 112: [tensor(-0.3887), tensor(-0.0307), tensor(-0.2964), tensor(-0.1637), tensor(-0.1085), tensor(-0.0246), tensor(-0.1214), tensor(0.0647), tensor(3.9267e-05), tensor(-0.0307), tensor(-0.1418), tensor(-0.5402), tensor(0.0307), tensor(0.0401), tensor(0.0252), tensor(0.0114), tensor(-0.2160), tensor(0.0745), tensor(-0.1804), tensor(-0.4041), tensor(-0.2509), tensor(-0.1950), tensor(-0.2385), tensor(-0.2102), tensor(-0.4722), tensor(-0.4593), tensor(-0.1827), tensor(-0.2375), tensor(-0.2376), tensor(0.0138)], 113: [tensor(0.0347), tensor(0.0437), tensor(-0.2181), tensor(0.0445), tensor(0.0241), tensor(0.0316), tensor(0.0350), tensor(0.0381), tensor(-0.1803), tensor(-0.1736), tensor(0.0629), tensor(0.0017), tensor(-0.0043), tensor(-0.1332), tensor(0.0441), tensor(0.0454), tensor(0.0250), tensor(0.0818), tensor(0.0380), tensor(0.0131), tensor(0.0777), tensor(-0.2679), tensor(0.0038), tensor(0.0544), tensor(-0.2197), tensor(0.0243), tensor(0.0448), tensor(0.0342), tensor(0.0419), tensor(0.0581)], 114: [tensor(0.0699), tensor(-0.2036), tensor(0.0079), tensor(-0.2647), tensor(0.0195), tensor(-0.3465), tensor(0.0519), tensor(-0.2119), tensor(-0.3289), tensor(-0.2445), tensor(0.0321), tensor(0.0085), tensor(-0.2042), tensor(0.0450), tensor(-0.1195), tensor(0.0005), tensor(0.0227), tensor(0.0332), tensor(0.0344), tensor(-0.3118), tensor(-0.1962), tensor(-0.1729), tensor(-0.1415), tensor(-0.1940), tensor(-0.0219), tensor(0.0786), tensor(0.0087), tensor(0.0831), tensor(0.0239), tensor(0.0424)], 115: [tensor(-0.4055), tensor(-0.1110), tensor(-0.0528), tensor(-0.2195), tensor(0.0381), tensor(0.0631), tensor(-0.2883), tensor(-0.2431), tensor(-0.2666), tensor(0.0515), tensor(0.0462), tensor(-0.2469), tensor(-0.6362), tensor(-0.2955), tensor(-0.5186), tensor(-0.1582), tensor(-0.2139), tensor(-0.1899), tensor(-0.4630), tensor(-0.1767), tensor(-0.1756), tensor(-0.7773), tensor(-0.5077), tensor(-0.4560), tensor(-0.1444), tensor(0.0640), tensor(0.0225), tensor(-0.6215), tensor(-0.4587), tensor(-0.6310)], 116: [tensor(0.0655), tensor(-0.0222), tensor(0.0404), tensor(0.0439), tensor(-0.1487), tensor(0.0164), tensor(-0.1796), tensor(0.0168), tensor(0.0676), tensor(-0.1997), tensor(0.0437), tensor(0.0815), tensor(-0.0937), tensor(-0.0142), tensor(-0.0094), tensor(0.0369), tensor(-0.1600), tensor(-0.3439), tensor(-0.1505), tensor(0.0593), tensor(0.0594), tensor(-0.0240), tensor(0.0491), tensor(-0.1466), tensor(-0.1426), tensor(0.0011), tensor(-0.2091), tensor(0.0541), tensor(-0.1780), tensor(-0.1282)], 117: [tensor(-0.1852), tensor(-0.1663), tensor(-0.2679), tensor(0.0442), tensor(-0.1445), tensor(-0.1455), tensor(-0.2059), tensor(-0.4379), tensor(-0.2506), tensor(-0.2605), tensor(-0.1633), tensor(0.0201), tensor(0.0432), tensor(-0.1188), tensor(-0.2874), tensor(0.0333), tensor(-0.1881), tensor(0.0229), tensor(-0.2090), tensor(-0.2355), tensor(0.0445), tensor(-0.1225), tensor(0.0697), tensor(0.0456), tensor(-0.5945), tensor(-0.1243), tensor(-0.1791), tensor(0.0213), tensor(0.0174), tensor(-0.3253)], 118: [tensor(-0.1776), tensor(0.0280), tensor(0.0528), tensor(-0.1494), tensor(0.0545), tensor(0.0440), tensor(-0.1167), tensor(0.0810), tensor(0.0188), tensor(0.0472), tensor(-0.1147), tensor(-0.1778), tensor(0.0462), tensor(0.0429), tensor(0.0797), tensor(-0.6379), tensor(0.0349), tensor(-0.0849), tensor(0.0686), tensor(0.0079), tensor(0.0408), tensor(-0.0229), tensor(-0.1700), tensor(0.0353), tensor(0.0333), tensor(0.0561), tensor(0.0199), tensor(0.0609), tensor(-0.1014), tensor(0.0344)], 119: [tensor(0.0303), tensor(-0.1184), tensor(0.0440), tensor(0.0235), tensor(0.0752), tensor(0.0750), tensor(0.0265), tensor(0.0351), tensor(0.0561), tensor(0.0648), tensor(0.0877), tensor(-0.3910), tensor(-0.2141), tensor(-0.0016), tensor(0.0387), tensor(-0.0012), tensor(0.0405), tensor(0.0455), tensor(0.0405), tensor(0.0672), tensor(0.0490), tensor(0.0506), tensor(0.0537), tensor(0.0368), tensor(0.0731), tensor(0.0253), tensor(0.0173), tensor(0.0322), tensor(0.0604), tensor(0.0519)]}\n"
     ]
    }
   ],
   "source": [
    "returns = meta_agent.sample_returns(tasks=tasks, repeats_per_task=30)\n",
    "print(returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4c0dda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(returns.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e81aa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/121 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fabia\\Documents\\GitHub\\MetaStableBaselines3\\proj_code\\stable-baselines3-master\\stable-baselines3-master\\stable_baselines3\\common\\on_policy_algorithm.py:552: RuntimeWarning: The iteration is not making good progress, as measured by the \n",
      " improvement from the last ten iterations.\n",
      "  epsilon = fsolve(self._theorem2_epsiloneq, starting_point, args=(k,K,n,gamma,eta))\n",
      " 98%|█████████▊| 118/121 [02:08<00:03,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.05982162]), np.float64(-1.0329530692093885))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epsilon, guarantee =  meta_agent.task_risk_SMC_c2(gamma, eta, 0, returns, (-0.6,0.6))#(a,b)) #TODO: intereswtingly too conservative bounds here may make c3 better!\n",
    "print((epsilon, guarantee))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "20852f83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/121 [00:00<?, ?it/s]C:\\Users\\fabia\\Documents\\GitHub\\MetaStableBaselines3\\proj_code\\stable-baselines3-master\\stable-baselines3-master\\stable_baselines3\\common\\on_policy_algorithm.py:552: RuntimeWarning: The iteration is not making good progress, as measured by the \n",
      " improvement from the last ten iterations.\n",
      "  epsilon = fsolve(self._theorem2_epsiloneq, starting_point, args=(k,K,n,gamma,eta))\n",
      " 98%|█████████▊| 118/121 [01:07<00:01,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.05982162]), np.float64(-0.9498401623959329))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epsilon, guarantee =  meta_agent.task_risk_SMC_c2(gamma, eta, 0, returns, (-0.8,0.1))#(a,b)) #TODO: intereswtingly too conservative bounds here may make c3 better!\n",
    "print((epsilon, guarantee))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "729fd5eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 109/111 [00:51<00:00,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.15948922]), np.float64(-0.6057993626587902))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epsilon, guarantee =  meta_agent.task_risk_SMC_c2(gamma, eta, 10, returns, (-0.6,0.6))#(a,b)) #TODO: intereswtingly too conservative bounds here may make c3 better!\n",
    "print((epsilon, guarantee))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3fde5e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 113/116 [01:07<00:01,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.11160045]), np.float64(-0.6065565687413004))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epsilon, guarantee =  meta_agent.task_risk_SMC_c2(gamma, eta, 5, returns, (-0.8,0.1))#(a,b)) #TODO: intereswtingly too conservative bounds here may make c3 better!\n",
    "print((epsilon, guarantee))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7118a4d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 109/111 [00:59<00:01,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.15948922]), np.float64(-0.5226864558453348))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epsilon, guarantee =  meta_agent.task_risk_SMC_c2(gamma, eta, 10, returns, (-0.8,0.1))#(a,b)) #TODO: intereswtingly too conservative bounds here may make c3 better!\n",
    "print((epsilon, guarantee))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5396ccf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [03:22<00:00,  5.06s/it]\n"
     ]
    }
   ],
   "source": [
    "bounding_returns = meta_agent.sample_returns(tasks=40, repeats_per_task=1)\n",
    "bounding_returns = [i[0] for i in bounding_returns.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "754cab4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120/120 [13:37<00:00,  6.81s/it]\n"
     ]
    }
   ],
   "source": [
    "more_bounding_returns = meta_agent.sample_returns(tasks=120, repeats_per_task=1)\n",
    "bounding_returns = bounding_returns+ [i[0] for i in more_bounding_returns.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "55b03cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor(-0.9683), tensor(0.0986))\n",
      "100000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(0.012512262746522396)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = min(bounding_returns)\n",
    "b = max(bounding_returns)\n",
    "n_br = 100_000#len(bounding_returns)\n",
    "print((a,b))\n",
    "print(n_br)\n",
    "x = np.power(1/n_br, n_br/(n_br-1))\n",
    "gamma_hat = 2*(1+x-np.power(x,1/n_br))\n",
    "gamma_hat*50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f585918b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma_2=0.7913130471912166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 28/121 [00:04<00:14,  6.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((24, array([0.8190917])), tensor(-0.9961))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epsilon, guarantee =  meta_agent.task_risk_SMC_c3(gamma, 0.7, k, bounding_returns, returns) #small max ks just to cehck what gamma_2 ends up as\n",
    "print((epsilon, guarantee))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b7db1f6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma_2=0.7913130471912166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/121 [00:00<?, ?it/s]C:\\Users\\fabia\\Documents\\GitHub\\MetaStableBaselines3\\proj_code\\stable-baselines3-master\\stable-baselines3-master\\stable_baselines3\\common\\on_policy_algorithm.py:552: RuntimeWarning: The iteration is not making good progress, as measured by the \n",
      " improvement from the last ten iterations.\n",
      "  epsilon = fsolve(self._theorem2_epsiloneq, starting_point, args=(k,K,n,gamma,eta))\n",
      " 17%|█▋        | 20/121 [00:02<00:14,  6.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((18, array([0.90689483])), tensor(-0.9961))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epsilon, guarantee =  meta_agent.task_risk_SMC_c3(gamma, 0.07, k, bounding_returns, returns) #small max ks just to cehck what gamma_2 ends up as\n",
    "print((epsilon, guarantee))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d62b6ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma_2=0.9706507589896629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]C:\\Users\\fabia\\Documents\\GitHub\\MetaStableBaselines3\\proj_code\\stable-baselines3-master\\stable-baselines3-master\\stable_baselines3\\common\\on_policy_algorithm.py:552: RuntimeWarning: The iteration is not making good progress, as measured by the \n",
      " improvement from the last ten iterations.\n",
      "  epsilon = fsolve(self._theorem2_epsiloneq, starting_point, args=(k,K,n,gamma,eta))\n",
      "100%|██████████| 3/3 [00:04<00:00,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-1, tensor(-0.9730))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epsilon, guarantee =  meta_agent.task_risk_SMC_c3(gamma, eta, k, bounding_returns, returns, max_Ks=2)\n",
    "print((epsilon, guarantee))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projdist",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
